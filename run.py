
import gradio as gr
import logging
import os
import time
import datetime
from config_manager import EnhancedConfigManager
from config_ui import ConfigUI
from version import get_version, get_version_info

# Try to import optional dependencies
try:
    from write_story_enhanced import write_fantasy_novel, StoryWriter
    from author import create_cover_image, create_epub
    HAS_STORY_WRITER = True
except ImportError as e:
    print(f"âš ï¸ Story writer dependencies not available: {e}")
    HAS_STORY_WRITER = False
    
    # Create dummy functions for missing dependencies
    def write_fantasy_novel(*args, **kwargs):
        raise gr.Error("Story writer dependencies not installed. Please install required packages.")
    
    def create_cover_image(*args, **kwargs):
        return ""
    
    def create_epub(*args, **kwargs):
        return ""
    
    class StoryWriter:
        def write_fantasy_novel(self, *args, **kwargs):
            raise gr.Error("Story writer dependencies not installed. Please install required packages.")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
config_manager = EnhancedConfigManager()
config_ui = ConfigUI()

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æä¾›å•†
def check_providers():
    """æ£€æŸ¥æä¾›å•†é…ç½®"""
    status = config_manager.provider_manager.get_provider_status()
    available_providers = [name for name, data in status.items() if data.get('api_key_set', False)]
    return len(available_providers) > 0

def save_novel_to_output(title, chapters, chapter_titles, provider_name, model_name, total_words, novel_id):
    """ä¿å­˜å®Œæ•´å°è¯´åˆ°outputæ–‡ä»¶å¤¹"""
    try:
        # åˆ›å»ºoutputæ–‡ä»¶å¤¹
        output_dir = os.path.join(os.getcwd(), "output")
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            logger.info(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
        
        # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨æ—¶é—´æˆ³é¿å…é‡åï¼‰
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_title = title.replace(" ", "_").replace("/", "_").replace("\\", "_")
        filename = f"{safe_title}_{timestamp}.txt"
        filepath = os.path.join(output_dir, filename)
        
        # æ„å»ºå®Œæ•´å°è¯´å†…å®¹
        novel_content = f"""
===============================================================================
                            {title}
===============================================================================

ğŸ“š å°è¯´ä¿¡æ¯:
â€¢ æ ‡é¢˜: {title}
â€¢ ç« èŠ‚æ•°: {len(chapters)}
â€¢ æ€»å­—æ•°: {total_words:,}å­—
â€¢ å¹³å‡æ¯ç« : {total_words//len(chapters):,}å­—
â€¢ åˆ›ä½œæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â€¢ AIæä¾›å•†: {provider_name}
â€¢ ä½¿ç”¨æ¨¡å‹: {model_name}
â€¢ å°è¯´ID: {novel_id}

===============================================================================
                                ç›®å½•
===============================================================================

"""
        
        # æ·»åŠ ç›®å½•
        for i, chapter_title_dict in enumerate(chapter_titles):
            chapter_title = list(chapter_title_dict.keys())[0]
            novel_content += f"ç¬¬{i+1}ç« : {chapter_title}\n"
        
        novel_content += "\n"
        
        # æ·»åŠ ç« èŠ‚å†…å®¹
        for i, chapter in enumerate(chapters):
            chapter_title = list(chapter_titles[i].keys())[0]
            chapter_content = chapter
            
            novel_content += f"""
===============================================================================
                            {chapter_title}
===============================================================================

{chapter_content}

"""
        
        # æ·»åŠ ç»“å°¾ä¿¡æ¯
        novel_content += f"""
===============================================================================
                              åˆ›ä½œå®Œæˆ
===============================================================================

ğŸ“Š åˆ›ä½œç»Ÿè®¡:
â€¢ å®Œæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â€¢ æ€»å­—æ•°: {total_words:,}å­—
â€¢ ç« èŠ‚æ•°: {len(chapters)}ç« 
â€¢ AIæä¾›å•†: {provider_name}
â€¢ ä½¿ç”¨æ¨¡å‹: {model_name}

æ„Ÿè°¢ä½¿ç”¨ StoryGenius AI å°è¯´åˆ›ä½œå¹³å°!
é¡¹ç›®åœ°å€: https://github.com/Crossme0809/gpt-story-genius
"""
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(novel_content)
        
        logger.info(f"ğŸ“„ å°è¯´å·²ä¿å­˜åˆ°: {filepath}")
        logger.info(f"ğŸ“Š ä¿å­˜æ–‡ä»¶å¤§å°: {os.path.getsize(filepath)} å­—èŠ‚")
        
        # åˆ›å»ºç« èŠ‚æ–‡ä»¶å¤¹å¹¶ä¿å­˜å„ç« èŠ‚
        chapters_dir = os.path.join(output_dir, f"{safe_title}_{timestamp}_chapters")
        os.makedirs(chapters_dir, exist_ok=True)
        
        chapter_files = []
        for i, chapter in enumerate(chapters):
            chapter_title = list(chapter_titles[i].keys())[0]
            safe_chapter_title = chapter_title.replace(" ", "_").replace("/", "_").replace("\\", "_")
            chapter_filename = f"ç¬¬{i+1:02d}ç« _{safe_chapter_title}.txt"
            chapter_filepath = os.path.join(chapters_dir, chapter_filename)
            
            chapter_content = f"""
{chapter_title}

{chapter}

---
å­—æ•°: {len(chapter)}å­—
åˆ›ä½œæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            with open(chapter_filepath, 'w', encoding='utf-8') as f:
                f.write(chapter_content)
            
            chapter_files.append(chapter_filename)
        
        logger.info(f"ğŸ“ ç« èŠ‚æ–‡ä»¶å·²ä¿å­˜åˆ°: {chapters_dir}")
        
        # åŒæ—¶ä¿å­˜ä¸€ä¸ªJSONå…ƒæ•°æ®æ–‡ä»¶
        metadata_filename = f"{safe_title}_{timestamp}_metadata.json"
        metadata_filepath = os.path.join(output_dir, metadata_filename)
        
        import json
        metadata = {
            "title": title,
            "chapters": len(chapters),
            "total_words": total_words,
            "average_words_per_chapter": total_words // len(chapters),
            "created_time": datetime.datetime.now().isoformat(),
            "provider": provider_name,
            "model": model_name,
            "novel_id": novel_id,
            "chapter_titles": [list(ct.keys())[0] for ct in chapter_titles],
            "text_file": filename,
            "chapters_directory": f"{safe_title}_{timestamp}_chapters",
            "chapter_files": chapter_files,
            "generated_by": "StoryGenius AI",
            "version": get_version()
        }
        
        with open(metadata_filepath, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“‹ å…ƒæ•°æ®å·²ä¿å­˜åˆ°: {metadata_filepath}")
        
        return filepath
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å°è¯´åˆ°è¾“å‡ºæ–‡ä»¶å¤¹å¤±è´¥: {e}")
        return None

def save_generation_process(generation_log, safe_title, timestamp):
    """ä¿å­˜ç”Ÿæˆè¿‡ç¨‹åˆ°æ–‡ä»¶"""
    try:
        output_dir = os.path.join(os.getcwd(), "output")
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # ä¿å­˜ä¸ºMarkdownæ ¼å¼
        md_filename = f"{safe_title}_{timestamp}_ç”Ÿæˆè¿‡ç¨‹.md"
        md_filepath = os.path.join(output_dir, md_filename)
        
        # æ„å»ºMarkdownå†…å®¹
        md_content = f"""# ğŸ“ å°è¯´ç”Ÿæˆè¿‡ç¨‹è®°å½•

## ğŸ“Š åŸºæœ¬ä¿¡æ¯
- **å¼€å§‹æ—¶é—´**: {generation_log['start_time']}
- **ç”¨æˆ·æç¤º**: {generation_log['user_prompt']}
- **ç« èŠ‚æ•°**: {generation_log['num_chapters']}
- **å†™ä½œé£æ ¼**: {generation_log['writing_style']}
- **AIæä¾›å•†**: {generation_log['provider']}
- **ä½¿ç”¨æ¨¡å‹**: {generation_log['model']}

---

## ğŸ­ æƒ…èŠ‚ç”Ÿæˆé˜¶æ®µ

### ğŸ“ å€™é€‰æƒ…èŠ‚
"""
        
        for i, plot in enumerate(generation_log['plots']):
            if plot.strip():
                md_content += f"{i+1}. {plot.strip()}\n\n"
        
        if generation_log['selected_plot']:
            md_content += f"""
### âœ… é€‰å®šæƒ…èŠ‚
{generation_log['selected_plot']}

"""
        
        if generation_log['improved_plot']:
            md_content += f"""
### ğŸ”„ ä¼˜åŒ–åæƒ…èŠ‚
{generation_log['improved_plot']}

"""
        
        if generation_log['title']:
            md_content += f"""
---

## ğŸ“– å°è¯´æ ‡é¢˜
**{generation_log['title']}**

"""
        
        if generation_log['storyline']:
            md_content += f"""
---

## ğŸ“‹ æ•…äº‹çº¿
```json
{generation_log['storyline']}
```

"""
        
        # ç« èŠ‚ç”Ÿæˆè¿‡ç¨‹
        if generation_log['chapters']:
            md_content += """
---

## ğŸ“š ç« èŠ‚ç”Ÿæˆè¿‡ç¨‹

"""
            for chapter_info in generation_log['chapters']:
                md_content += f"""
### {chapter_info['title']}
- **ç”Ÿæˆæ—¶é—´**: {chapter_info['timestamp']}
- **å­—æ•°**: {chapter_info['word_count']:,}å­—
- **Tokenæ¶ˆè€—**: {chapter_info.get('tokens', 0):,}
- **ç”Ÿæˆæ—¶é•¿**: {chapter_info.get('duration', 0):.2f}ç§’

"""
                if chapter_info.get('content_preview'):
                    md_content += f"""
**å†…å®¹é¢„è§ˆ**:
{chapter_info['content_preview']}...

"""
        
        # ç« èŠ‚æ‘˜è¦
        if generation_log['summaries']:
            md_content += """
---

## ğŸ“„ ç« èŠ‚æ‘˜è¦

"""
            for i, summary in enumerate(generation_log['summaries']):
                md_content += f"""
### ç¬¬{i+1}ç« æ‘˜è¦
{summary}

"""
        
        # ç”Ÿæˆæ­¥éª¤è®°å½•
        if generation_log['steps']:
            md_content += """
---

## ğŸ”„ è¯¦ç»†æ­¥éª¤è®°å½•

"""
            for step in generation_log['steps']:
                md_content += f"""
### {step['step_name']}
- **æ—¶é—´**: {step['timestamp']}
- **æè¿°**: {step.get('description', '')}
- **è€—æ—¶**: {step.get('duration', 0):.2f}ç§’

"""
        
        md_content += f"""
---

## ğŸ“Š ç”Ÿæˆå®Œæˆ
- **å®Œæˆæ—¶é—´**: {datetime.datetime.now().isoformat()}
- **æ€»è€—æ—¶**: {(datetime.datetime.now() - datetime.datetime.fromisoformat(generation_log['start_time'])).total_seconds():.2f}ç§’
- **ç”Ÿæˆå·¥å…·**: StoryGenius AI v{get_version()}
"""
        
        # ä¿å­˜æ–‡ä»¶
        with open(md_filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        logger.info(f"ğŸ“‹ ç”Ÿæˆè¿‡ç¨‹å·²ä¿å­˜åˆ°: {md_filepath}")
        return md_filepath
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜ç”Ÿæˆè¿‡ç¨‹å¤±è´¥: {e}")
        return None

def update_generation_log(generation_log, step_name, **kwargs):
    """æ›´æ–°ç”Ÿæˆè¿‡ç¨‹è®°å½•"""
    step_record = {
        "step_name": step_name,
        "timestamp": datetime.datetime.now().isoformat(),
        "description": kwargs.get('description', ''),
        "duration": kwargs.get('duration', 0)
    }
    generation_log['steps'].append(step_record)
    
    # æ ¹æ®æ­¥éª¤ç±»å‹æ›´æ–°ç›¸åº”å­—æ®µ
    if 'plots' in kwargs:
        generation_log['plots'] = kwargs['plots']
    if 'selected_plot' in kwargs:
        generation_log['selected_plot'] = kwargs['selected_plot']
    if 'improved_plot' in kwargs:
        generation_log['improved_plot'] = kwargs['improved_plot']
    if 'title' in kwargs:
        generation_log['title'] = kwargs['title']
    if 'storyline' in kwargs:
        generation_log['storyline'] = kwargs['storyline']
    if 'chapter_info' in kwargs:
        generation_log['chapters'].append(kwargs['chapter_info'])
    if 'summary' in kwargs:
        generation_log['summaries'].append(kwargs['summary'])
    
    return generation_log


def generate_novel(prompt, num_chapters, writing_style, provider_name, model_name):
    # è°ƒç”¨GPTå’ŒClaude APIï¼Œç”Ÿæˆå°è¯´ç»“æœ
    # prompt = "A kingdom hidden deep in the forest, where every tree is a portal to another world."
    # num_chapters = 2
    # writing_style = "Clear and easily understandable, similar to a young adult novel. Lots of dialogue."
    # model_name = "gpt-3.5-turbo-16k"
    if not prompt or not writing_style:
        raise gr.Error("æç¤ºè¯å’Œå†™ä½œé£æ ¼æ˜¯å¿…å¡«é¡¹")
    if num_chapters < 1:
        raise gr.Error("ç« èŠ‚æ•°å¿…é¡»å¤§äºç­‰äº1")
    
    # æ£€æŸ¥æä¾›å•†é…ç½®
    if not check_providers():
        raise gr.Error("è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®è‡³å°‘ä¸€ä¸ªAIæä¾›å•†çš„APIå¯†é’¥")

    num_chapters = int(num_chapters)
    
    # è½¬æ¢æä¾›å•†æ˜¾ç¤ºåç§°ä¸ºå†…éƒ¨é”®
    provider_map = {
        'DeepSeek': 'deepseek',
        'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
        'æ™ºè°±AI GLM': 'zhipu',
        'Google Gemini': 'gemini',
        'OpenRouter': 'openrouter',
        'LM Studio': 'lmstudio',
        'Claude': 'claude',
        'Grok': 'grok'
    }
    provider_key = provider_map.get(provider_name, provider_name.lower())
    
    # ä½¿ç”¨å¢å¼ºçš„å°è¯´åˆ›ä½œå™¨
    writer = StoryWriter()
    _, title, chapters, chapter_titles, chapter_tokens_list = writer.write_fantasy_novel(
        prompt, num_chapters, writing_style, provider_key, model_name
    )

    # ç”¨chapter_titlesä¸­çš„æ­£æ–‡å–ä»£ç« èŠ‚è¯´æ˜
    for i, chapter in enumerate(chapters):
        chapter_number_and_title = list(chapter_titles[i].keys())[0]
        chapter_titles[i] = {chapter_number_and_title: chapter}

    # æš‚æ—¶è·³è¿‡å°é¢ç”Ÿæˆï¼ˆåŠŸèƒ½ä¿ç•™ï¼Œä»¥åå®Œå–„ï¼‰
    image_url = None
    print("å°é¢ç”ŸæˆåŠŸèƒ½å·²æš‚æ—¶ç¦ç”¨")

    # ç”Ÿæˆå°è¯´ EPUB æ–‡ä»¶ï¼ˆä¸ä½¿ç”¨å°é¢ï¼‰
    file_url = create_epub(title, 'AI', chapter_titles, cover_image_path=None)
    print(f"Novel URL: {file_url}")

    # novel, file_path = write_fantasy_novel(prompt, num_chapters, writing_style)
    return { "image_url": image_url, "file_url": file_url }


def generate_output_with_progress(prompt, num_chapters, writing_style, provider_name, model_name):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„å°è¯´ç”Ÿæˆå‡½æ•°"""
    try:
        # éªŒè¯è¾“å…¥
        if not prompt or not writing_style:
            raise gr.Error("æç¤ºè¯å’Œå†™ä½œé£æ ¼æ˜¯å¿…å¡«é¡¹")
        if num_chapters < 1:
            raise gr.Error("ç« èŠ‚æ•°å¿…é¡»å¤§äºç­‰äº1")
        
        # æ£€æŸ¥æä¾›å•†é…ç½®
        if not check_providers():
            raise gr.Error("è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®è‡³å°‘ä¸€ä¸ªAIæä¾›å•†çš„APIå¯†é’¥")

        num_chapters = int(num_chapters)
        
        # è½¬æ¢æä¾›å•†æ˜¾ç¤ºåç§°ä¸ºå†…éƒ¨é”®
        provider_map = {
            'DeepSeek': 'deepseek',
            'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
            'æ™ºè°±AI GLM': 'zhipu',
            'Google Gemini': 'gemini',
            'OpenRouter': 'openrouter',
            'LM Studio': 'lmstudio',
            'Claude': 'claude',
            'Grok': 'grok'
        }
        provider_key = provider_map.get(provider_name, provider_name.lower())
        
        # ç”Ÿæˆé˜¶æ®µè¿›åº¦è®¡ç®—ï¼ˆå¢åŠ æ‘˜è¦ç”Ÿæˆæ­¥éª¤å’Œæ–‡ä»¶ä¿å­˜æ­¥éª¤ï¼‰
        total_steps = 5 + num_chapters + (num_chapters - 1) + 2  # æƒ…èŠ‚ç”Ÿæˆã€é€‰æ‹©ã€æ”¹è¿›ã€æ ‡é¢˜ã€æ•…äº‹çº¿ + å„ç« èŠ‚ + æ‘˜è¦ç”Ÿæˆï¼ˆé™¤æœ€åä¸€ç« ï¼‰+ EPUBç”Ÿæˆ + æ–‡æœ¬ä¿å­˜
        current_step = 0
        current_words = 0
        
        # åˆ›å»ºç”Ÿæˆè¿‡ç¨‹è®°å½•
        generation_log = {
            "start_time": datetime.datetime.now().isoformat(),
            "user_prompt": prompt,
            "num_chapters": num_chapters,
            "writing_style": writing_style,
            "provider": provider_name,
            "model": model_name,
            "steps": [],
            "plots": [],
            "selected_plot": "",
            "improved_plot": "",
            "title": "",
            "storyline": "",
            "chapters": [],
            "summaries": []
        }
        
        # å®šä¹‰è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(step_name, step_desc="", chapter_completed=None, chapter_content="", token_info=None, generation_info=None):
            nonlocal current_step, current_words
            current_step += 1
            if chapter_content:
                current_words += len(str(chapter_content))
            
            progress_percent = int((current_step / total_steps) * 100)
            
            stats = {
                "å·²ç”Ÿæˆç« èŠ‚": chapter_completed if chapter_completed is not None else 0,
                "é¢„è®¡æ€»ç« èŠ‚": num_chapters,
                "ç”Ÿæˆè¿›åº¦": f"{progress_percent}%",
                "å½“å‰å­—æ•°": current_words
            }
            
            # æ„å»ºè¯¦ç»†çš„ç”ŸæˆçŠ¶æ€ä¿¡æ¯
            detailed_status = f"ğŸ”„ {step_name}\n\n"
            
            # åˆ›å»ºæ–‡å­—è¿›åº¦æ¡
            progress_bar_length = 20
            filled_length = int(progress_bar_length * progress_percent / 100)
            progress_bar = "â–ˆ" * filled_length + "â–‘" * (progress_bar_length - filled_length)
            detailed_status += f"ğŸ“Š æ€»ä½“è¿›åº¦: {progress_percent}% [{progress_bar}]\n"
            detailed_status += f"ğŸ“ˆ æ­¥éª¤è¿›åº¦: {current_step}/{total_steps} æ­¥éª¤\n"
            
            # ç« èŠ‚è¿›åº¦æ¡
            if num_chapters > 0:
                chapter_progress_percent = int((chapter_completed if chapter_completed is not None else 0) / num_chapters * 100)
                chapter_filled = int(progress_bar_length * chapter_progress_percent / 100)
                chapter_progress_bar = "â–ˆ" * chapter_filled + "â–‘" * (progress_bar_length - chapter_filled)
                detailed_status += f"ğŸ“š ç« èŠ‚è¿›åº¦: {chapter_progress_percent}% [{chapter_progress_bar}]\n"
                detailed_status += f"ğŸ“– ç« èŠ‚çŠ¶æ€: {chapter_completed if chapter_completed is not None else 0}/{num_chapters} ç« \n"
            
            detailed_status += f"ğŸ”¢ å­—æ•°ç»Ÿè®¡: {current_words:,}å­—\n"
            detailed_status += f"ğŸ’¡ å½“å‰æ­¥éª¤: {step_name}\n"
            
            if step_desc:
                detailed_status += f"ğŸ“‹ æ­¥éª¤æè¿°: {step_desc}\n"
            
            if token_info:
                detailed_status += f"\nğŸ”¢ Tokenç»Ÿè®¡:\n"
                detailed_status += f"  â€¢ è¾“å…¥Token: {token_info.get('input_tokens', 0):,}\n"
                detailed_status += f"  â€¢ è¾“å‡ºToken: {token_info.get('output_tokens', 0):,}\n"
                detailed_status += f"  â€¢ æ€»Token: {token_info.get('total_tokens', 0):,}\n"
            
            # æ·»åŠ ç”Ÿæˆè¿‡ç¨‹ä¿¡æ¯
            if generation_info:
                detailed_status += f"\nğŸ“‹ ç”Ÿæˆä¿¡æ¯:\n"
                if 'plots_count' in generation_info:
                    detailed_status += f"  â€¢ å€™é€‰æƒ…èŠ‚æ•°: {generation_info['plots_count']}\n"
                if 'title' in generation_info:
                    detailed_status += f"  â€¢ å°è¯´æ ‡é¢˜: {generation_info['title']}\n"
                if 'storyline_ready' in generation_info:
                    detailed_status += f"  â€¢ æ•…äº‹çº¿: {'å·²ç”Ÿæˆ' if generation_info['storyline_ready'] else 'ç”Ÿæˆä¸­'}\n"
            
            # æ„å»ºç« èŠ‚å®Œæˆæƒ…å†µ
            if chapter_completed is not None and chapter_completed > 0:
                chapter_info = f"ğŸ“– å·²å®Œæˆç« èŠ‚: {chapter_completed}/{num_chapters}\n\n"
                chapter_info += f"âœ… ç¬¬{chapter_completed}ç« åˆ›ä½œå®Œæˆ\n"
                if chapter_content:
                    chapter_preview = str(chapter_content)[:200] + "..." if len(str(chapter_content)) > 200 else str(chapter_content)
                    chapter_info += f"ğŸ“ å†…å®¹é¢„è§ˆ:\n{chapter_preview}\n\n"
                    chapter_info += f"ğŸ“Š æœ¬ç« å­—æ•°: {len(str(chapter_content))}å­—\n"
                
                if token_info:
                    chapter_info += f"ğŸ”¢ æœ¬ç« Tokenæ¶ˆè€—: {token_info.get('total_tokens', 0):,}\n"
                
                # å¦‚æœæœ‰å¤šä¸ªç« èŠ‚ï¼Œæ˜¾ç¤ºæ€»ä½“è¿›åº¦
                if chapter_completed > 1:
                    chapter_info += f"\nğŸ“ˆ æ€»ä½“è¿›åº¦: {(chapter_completed/num_chapters)*100:.1f}%"
            else:
                chapter_info = f"ğŸ“– å‡†å¤‡å¼€å§‹ç« èŠ‚åˆ›ä½œ...\n\n"
                chapter_info += f"ğŸ“‹ è®¡åˆ’ç« èŠ‚æ•°: {num_chapters}\n"
                chapter_info += f"ğŸ“ å½“å‰é˜¶æ®µ: {step_name}"
            
            # ç®€åŒ–çš„æ—¥å¿—ä¿¡æ¯
            log_msg = f"ğŸ“ {step_name}"
            if chapter_completed is not None:
                log_msg += f" - å·²å®Œæˆç¬¬{chapter_completed}ç« "
                if token_info:
                    log_msg += f" (Token: {token_info.get('total_tokens', 0):,})"
            
            # æ„å»ºç”Ÿæˆè¿‡ç¨‹æ˜¾ç¤ºä¿¡æ¯
            process_info = f"ğŸ” ç”Ÿæˆè¿‡ç¨‹è¿½è¸ª\n\n"
            process_info += f"ğŸ“Š å½“å‰æ­¥éª¤: {step_name}\n"
            process_info += f"â° æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}\n\n"
            
            if generation_log['plots']:
                process_info += f"ğŸ­ å€™é€‰æƒ…èŠ‚: {len(generation_log['plots'])}ä¸ª\n"
            if generation_log['selected_plot']:
                process_info += f"âœ… é€‰å®šæƒ…èŠ‚: {generation_log['selected_plot'][:50]}...\n"
            if generation_log['title']:
                process_info += f"ğŸ“– å°è¯´æ ‡é¢˜: {generation_log['title']}\n"
            if generation_log['chapters']:
                process_info += f"ğŸ“š å·²å®Œæˆç« èŠ‚: {len(generation_log['chapters'])}/{num_chapters}\n"
            if generation_log['summaries']:
                process_info += f"ğŸ“„ ç”Ÿæˆæ‘˜è¦: {len(generation_log['summaries'])}ä¸ª\n"
            
            return (detailed_status, chapter_info, stats, log_msg, process_info, None, None)
        
        # åˆå§‹çŠ¶æ€
        initial_detailed_status = f"ğŸ”„ åˆå§‹åŒ–ä¸­...\n\nğŸ“Š å½“å‰è¿›åº¦: 0% (0/{total_steps})\nğŸ“š ç« èŠ‚çŠ¶æ€: 0/{num_chapters}\nğŸ”¢ å­—æ•°ç»Ÿè®¡: 0å­—\nğŸ’¡ å½“å‰æ­¥éª¤: å‡†å¤‡å¼€å§‹\nğŸ“‹ æ­¥éª¤æè¿°: æ­£åœ¨åˆå§‹åŒ–å°è¯´åˆ›ä½œç³»ç»Ÿ"
        initial_chapter_info = f"ğŸ“– å‡†å¤‡å¼€å§‹ç« èŠ‚åˆ›ä½œ...\n\nğŸ“‹ è®¡åˆ’ç« èŠ‚æ•°: {num_chapters}\nğŸ“ å½“å‰é˜¶æ®µ: ç³»ç»Ÿåˆå§‹åŒ–\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}"
        initial_process_info = f"ğŸ” ç”Ÿæˆè¿‡ç¨‹è¿½è¸ª\n\nğŸ“Š å½“å‰æ­¥éª¤: åˆå§‹åŒ–\nâ° æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}\n\nğŸ“‹ å³å°†å¼€å§‹å°è¯´åˆ›ä½œè¿‡ç¨‹..."
        yield (initial_detailed_status, initial_chapter_info, {"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": num_chapters, "ç”Ÿæˆè¿›åº¦": "0%", "å½“å‰å­—æ•°": 0}, "ğŸš€ å¼€å§‹åˆ›ä½œå°è¯´", initial_process_info, None, None)
        
        # ä½¿ç”¨å¢å¼ºçš„å°è¯´åˆ›ä½œå™¨
        writer = StoryWriter()
        
        # è®¾ç½®æä¾›å•†å’Œæ¨¡å‹
        if provider_key:
            try:
                writer.config_manager.provider_manager.switch_provider(provider_key)
                logger.info(f"åˆ‡æ¢åˆ°æä¾›å•†ï¼š{provider_key}")
            except Exception as e:
                logger.warning(f"åˆ‡æ¢æä¾›å•†å¤±è´¥ï¼š{e}")
        
        if model_name:
            writer.current_model = model_name
            logger.info(f"è®¾ç½®ä½¿ç”¨æ¨¡å‹ï¼š{model_name}")
        
        # æ‰‹åŠ¨æ‰§è¡Œå„ä¸ªæ­¥éª¤å¹¶æ›´æ–°è¿›åº¦
        yield progress_callback("ç”Ÿæˆæƒ…èŠ‚", "æ­£åœ¨ç”Ÿæˆå¤šä¸ªå€™é€‰æƒ…èŠ‚")
        plots = writer.generate_plots(prompt)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        update_generation_log(generation_log, "ç”Ÿæˆæƒ…èŠ‚", description="ç”Ÿæˆå¤šä¸ªå€™é€‰æƒ…èŠ‚", plots=plots)
        logger.info(f"ğŸ­ æˆåŠŸç”Ÿæˆ {len(plots)} ä¸ªå€™é€‰æƒ…èŠ‚")
        
        yield progress_callback("é€‰æ‹©æœ€ä½³æƒ…èŠ‚", "ä»å€™é€‰æƒ…èŠ‚ä¸­é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ")
        best_plot = writer.select_most_engaging(plots)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        update_generation_log(generation_log, "é€‰æ‹©æœ€ä½³æƒ…èŠ‚", description="ä»å€™é€‰æƒ…èŠ‚ä¸­é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ", selected_plot=best_plot)
        logger.info(f"âœ… å·²é€‰æ‹©æœ€ä½³æƒ…èŠ‚: {best_plot[:100]}...")
        
        yield progress_callback("ä¼˜åŒ–æƒ…èŠ‚", "è¿›ä¸€æ­¥å®Œå–„å’Œä¼˜åŒ–æƒ…èŠ‚")
        improved_plot = writer.improve_plot(best_plot)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        update_generation_log(generation_log, "ä¼˜åŒ–æƒ…èŠ‚", description="è¿›ä¸€æ­¥å®Œå–„å’Œä¼˜åŒ–æƒ…èŠ‚", improved_plot=improved_plot)
        logger.info(f"ğŸ”„ æƒ…èŠ‚ä¼˜åŒ–å®Œæˆ: {improved_plot[:100]}...")
        
        yield progress_callback("ç”Ÿæˆæ ‡é¢˜", "ä¸ºå°è¯´ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜")
        title = writer.get_title(improved_plot)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        update_generation_log(generation_log, "ç”Ÿæˆæ ‡é¢˜", description="ä¸ºå°è¯´ç”Ÿæˆå¸å¼•äººçš„æ ‡é¢˜", title=title)
        logger.info(f"ğŸ“– å°è¯´æ ‡é¢˜å·²ç”Ÿæˆ: {title}")
        
        yield progress_callback("ç”Ÿæˆæ•…äº‹çº¿", "åˆ›å»ºè¯¦ç»†çš„ç« èŠ‚å¤§çº²")
        storyline = writer.generate_storyline(improved_plot, num_chapters)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        update_generation_log(generation_log, "ç”Ÿæˆæ•…äº‹çº¿", description="åˆ›å»ºè¯¦ç»†çš„ç« èŠ‚å¤§çº²", storyline=storyline)
        logger.info(f"ğŸ“‹ æ•…äº‹çº¿å·²ç”Ÿæˆ: {len(storyline)} å­—ç¬¦")
        
        # è§£æç« èŠ‚æ ‡é¢˜
        import ast
        try:
            chapter_titles = ast.literal_eval(storyline)
        except Exception as e:
            logger.error(f"è§£ææ•…äº‹çº¿å¤±è´¥: {e}")
            chapter_titles = [
                {f"Chapter {i+1} - ç¬¬{i+1}ç« ": f"ç¬¬{i+1}ç« å†…å®¹"}
                for i in range(num_chapters)
            ]
        
        # åˆ›å»ºç« èŠ‚åˆ—è¡¨
        chapters = []
        
        # ç”Ÿæˆå”¯ä¸€çš„å°è¯´IDç”¨äºTokenä¼˜åŒ–
        from config import generate_uuid
        novel_id = generate_uuid()
        
        # å†™ç¬¬ä¸€ç« 
        yield progress_callback("å†™ä½œç¬¬ä¸€ç« ", f"æ­£åœ¨åˆ›ä½œ: {list(chapter_titles[0].keys())[0]}")
        first_chapter_start_time = time.time()
        first_chapter, first_chapter_tokens = writer.write_first_chapter(storyline, str(chapter_titles[0]), writing_style)
        first_chapter_duration = time.time() - first_chapter_start_time
        chapters.append(first_chapter)
        
        # ä¿å­˜ç¬¬ä¸€ç« å’Œæ‘˜è¦
        from config import save_novel_chapter, save_chapter_summary
        first_chapter_title = list(chapter_titles[0])[0]
        save_novel_chapter(novel_id, 0, first_chapter_title, first_chapter)
        first_chapter_summary = writer.summarize_chapter(first_chapter, first_chapter_title)
        save_chapter_summary(novel_id, 0, first_chapter_summary)
        
        # æ›´æ–°ç”Ÿæˆæ—¥å¿—
        chapter_info = {
            "title": first_chapter_title,
            "timestamp": datetime.datetime.now().isoformat(),
            "word_count": len(first_chapter),
            "tokens": first_chapter_tokens.get('total_tokens', 0),
            "duration": first_chapter_duration,
            "content_preview": first_chapter[:200]
        }
        update_generation_log(generation_log, "ç¬¬ä¸€ç« å®Œæˆ", description="ç¬¬ä¸€ç« åˆ›ä½œå®Œæˆ", chapter_info=chapter_info, summary=first_chapter_summary)
        logger.info(f"ğŸ“ ç¬¬ä¸€ç« ã€Š{first_chapter_title}ã€‹åˆ›ä½œå®Œæˆï¼Œå­—æ•°: {len(first_chapter)}")
        
        yield progress_callback("ç¬¬ä¸€ç« å®Œæˆ", "ç¬¬ä¸€ç« åˆ›ä½œå®Œæˆ", 1, first_chapter, first_chapter_tokens)
        
        # å†™å…¶ä½™ç« èŠ‚ - ä½¿ç”¨Tokenä¼˜åŒ–
        for i in range(num_chapters - 1):
            current_chapter_index = i + 1
            chapter_title = list(chapter_titles[i + 1].keys())[0]
            yield progress_callback(f"å†™ä½œç¬¬{i+2}ç« ", f"æ­£åœ¨åˆ›ä½œ: {chapter_title}")
            
            # æ„å»ºä¼˜åŒ–çš„ä¸Šä¸‹æ–‡
            optimized_context = writer.build_optimized_context(novel_id, current_chapter_index, recent_chapters_count=2)
            
            chapter, chapter_tokens = writer.write_chapter(optimized_context, storyline, str(chapter_titles[i + 1]))
            
            # æ£€æŸ¥ç« èŠ‚é•¿åº¦
            if len(str(chapter)) < 100:
                yield progress_callback(f"é‡å†™ç¬¬{i+2}ç« ", "ç« èŠ‚é•¿åº¦ä¸è¶³ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ")
                chapter, chapter_tokens = writer.write_chapter(optimized_context, storyline, str(chapter_titles[i + 1]))
            
            chapters.append(chapter)
            
            # ä¿å­˜ç« èŠ‚
            save_novel_chapter(novel_id, current_chapter_index, chapter_title, chapter)
            
            # ç”Ÿæˆå¹¶ä¿å­˜æ‘˜è¦ï¼ˆé™¤äº†æœ€åä¸€ç« ï¼‰
            chapter_summary = None
            if current_chapter_index < num_chapters - 1:
                chapter_summary = writer.summarize_chapter(chapter, chapter_title)
                save_chapter_summary(novel_id, current_chapter_index, chapter_summary)
            
            # æ›´æ–°ç”Ÿæˆæ—¥å¿—
            chapter_info = {
                "title": chapter_title,
                "timestamp": datetime.datetime.now().isoformat(),
                "word_count": len(chapter),
                "tokens": chapter_tokens.get('total_tokens', 0),
                "duration": 0,  # å¯ä»¥æ·»åŠ è®¡æ—¶
                "content_preview": chapter[:200]
            }
            update_generation_log(generation_log, f"ç¬¬{i+2}ç« å®Œæˆ", description=f"ç¬¬{i+2}ç« åˆ›ä½œå®Œæˆ", chapter_info=chapter_info, summary=chapter_summary)
            logger.info(f"ğŸ“ ç¬¬{i+2}ç« ã€Š{chapter_title}ã€‹åˆ›ä½œå®Œæˆï¼Œå­—æ•°: {len(chapter)}")
            
            yield progress_callback(f"ç¬¬{i+2}ç« å®Œæˆ", f"ç¬¬{i+2}ç« åˆ›ä½œå®Œæˆ", i+2, chapter, chapter_tokens)

        # ç”¨chapter_titlesä¸­çš„æ­£æ–‡å–ä»£ç« èŠ‚è¯´æ˜
        for i, chapter in enumerate(chapters):
            chapter_number_and_title = list(chapter_titles[i].keys())[0]
            chapter_titles[i] = {chapter_number_and_title: chapter}

        # ç”ŸæˆEPUBæ–‡ä»¶
        yield progress_callback("ç”ŸæˆEPUBæ–‡ä»¶", "æ­£åœ¨åˆ›å»ºç”µå­ä¹¦æ–‡ä»¶")
        file_url = create_epub(title, 'AI', chapter_titles, cover_image_path=None)
        
        # ä¿å­˜å®Œæ•´å°è¯´åˆ°outputæ–‡ä»¶å¤¹
        yield progress_callback("ä¿å­˜å°è¯´æ–‡ä»¶", "æ­£åœ¨ä¿å­˜å®Œæ•´å°è¯´åˆ°outputæ–‡ä»¶å¤¹")
        total_words = sum(len(str(chapter)) for chapter in chapters)
        saved_filepath = save_novel_to_output(title, chapters, chapter_titles, provider_name, model_name, total_words, novel_id)
        
        # ä¿å­˜ç”Ÿæˆè¿‡ç¨‹æ–‡ä»¶
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_title = title.replace(" ", "_").replace("/", "_").replace("\\", "_")
        generation_log['end_time'] = datetime.datetime.now().isoformat()
        process_filepath = save_generation_process(generation_log, safe_title, timestamp)
        
        # å®Œæˆ
        final_stats = {
            "å·²ç”Ÿæˆç« èŠ‚": len(chapters), 
            "é¢„è®¡æ€»ç« èŠ‚": num_chapters, 
            "ç”Ÿæˆè¿›åº¦": "100%", 
            "å½“å‰å­—æ•°": total_words,
            "å°è¯´æ ‡é¢˜": title
        }
        
        # æ›´æ–°æœ€ç»ˆçŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…å«ä¿å­˜è·¯å¾„
        save_info = f"\nğŸ“ æ–‡æœ¬æ–‡ä»¶: {saved_filepath}" if saved_filepath else "\nâš ï¸ æ–‡æœ¬æ–‡ä»¶ä¿å­˜å¤±è´¥"
        process_info = f"\nğŸ“‹ ç”Ÿæˆè¿‡ç¨‹: {process_filepath}" if process_filepath else "\nâš ï¸ ç”Ÿæˆè¿‡ç¨‹ä¿å­˜å¤±è´¥"
        
        final_detailed_status = f"âœ… å°è¯´åˆ›ä½œå®Œæˆ!\n\nğŸ“Š æœ€ç»ˆè¿›åº¦: 100% ({total_steps}/{total_steps})\nğŸ“š ç« èŠ‚çŠ¶æ€: {len(chapters)}/{num_chapters} å…¨éƒ¨å®Œæˆ\nğŸ”¢ æ€»å­—æ•°: {total_words:,}å­—\nğŸ’¡ å½“å‰æ­¥éª¤: åˆ›ä½œå®Œæˆ\nğŸ“‹ å°è¯´æ ‡é¢˜: {title}\nğŸ‰ çŠ¶æ€: åˆ›ä½œæˆåŠŸ{save_info}{process_info}"
        
        final_chapter_info = f"ğŸ“– æ‰€æœ‰ç« èŠ‚åˆ›ä½œå®Œæˆ!\n\nâœ… æˆåŠŸå®Œæˆ: {len(chapters)}ç« \nğŸ“Š æ€»å­—æ•°: {total_words:,}å­—\nğŸ“š å¹³å‡æ¯ç« : {total_words//len(chapters):,}å­—\nğŸ“– EPUBæ–‡ä»¶å·²ç”Ÿæˆ\nğŸ¯ å°è¯´æ ‡é¢˜: {title}{save_info}{process_info}"
        
        final_log = f"âœ… å°è¯´ã€Š{title}ã€‹ç”Ÿæˆå®Œæˆ\nğŸ“š å…±{len(chapters)}ç« ï¼Œæ€»å­—æ•°ï¼š{total_words}å­—\nğŸ“– EPUBæ–‡ä»¶å·²ç”Ÿæˆ\nğŸ“ æ–‡æœ¬æ–‡ä»¶å·²ä¿å­˜åˆ°outputæ–‡ä»¶å¤¹\nğŸ“‹ ç”Ÿæˆè¿‡ç¨‹å·²ä¿å­˜"
        
        final_process_info = f"ğŸ” ç”Ÿæˆè¿‡ç¨‹å®Œæˆ\n\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:\nâ€¢ å€™é€‰æƒ…èŠ‚: {len(generation_log['plots'])}ä¸ª\nâ€¢ å®Œæˆç« èŠ‚: {len(generation_log['chapters'])}/{num_chapters}\nâ€¢ ç”Ÿæˆæ‘˜è¦: {len(generation_log['summaries'])}ä¸ª\nâ€¢ æ€»æ­¥éª¤: {len(generation_log['steps'])}æ­¥\nâ€¢ åˆ›ä½œæ—¶é•¿: {(datetime.datetime.now() - datetime.datetime.fromisoformat(generation_log['start_time'])).total_seconds():.2f}ç§’\n\nğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°outputæ–‡ä»¶å¤¹"
        
        yield (final_detailed_status, final_chapter_info, final_stats, final_log, final_process_info, None, file_url)
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆå°è¯´æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        # ä¿å­˜éƒ¨åˆ†ç”Ÿæˆè¿‡ç¨‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        if 'generation_log' in locals():
            try:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                safe_title = generation_log.get('title', 'Failed_Novel').replace(" ", "_").replace("/", "_").replace("\\", "_")
                generation_log['end_time'] = datetime.datetime.now().isoformat()
                generation_log['error'] = str(e)
                save_generation_process(generation_log, f"{safe_title}_FAILED", timestamp)
                logger.info("ğŸ“‹ å·²ä¿å­˜éƒ¨åˆ†ç”Ÿæˆè¿‡ç¨‹åˆ°æ–‡ä»¶")
            except:
                logger.error("âŒ æ— æ³•ä¿å­˜é”™è¯¯æ—¶çš„ç”Ÿæˆè¿‡ç¨‹")
        
        error_detailed_status = f"âŒ ç”Ÿæˆå¤±è´¥!\n\nğŸ“Š è¿›åº¦çŠ¶æ€: é”™è¯¯\nğŸ“š ç« èŠ‚çŠ¶æ€: ç”Ÿæˆä¸­æ–­\nğŸ”¢ å­—æ•°ç»Ÿè®¡: {current_words:,}å­—\nğŸ’¡ å½“å‰æ­¥éª¤: å‘ç”Ÿé”™è¯¯\nğŸ“‹ é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...\nâš ï¸ çŠ¶æ€: åˆ›ä½œå¤±è´¥"
        error_chapter_info = f"âŒ åˆ›ä½œè¿‡ç¨‹ä¸­æ–­!\n\nğŸš« é”™è¯¯ç±»å‹: ç³»ç»Ÿå¼‚å¸¸\nğŸ“ é”™è¯¯è¯¦æƒ…: {str(e)[:150]}...\nğŸ”„ å»ºè®®: è¯·æ£€æŸ¥é…ç½®åé‡è¯•"
        error_process_info = f"ğŸ” ç”Ÿæˆè¿‡ç¨‹ä¸­æ–­\n\nâŒ é”™è¯¯å‘ç”Ÿ\nâ° æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}\nğŸš« é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...\n\nğŸ“‹ éƒ¨åˆ†ç”Ÿæˆè¿‡ç¨‹å·²ä¿å­˜åˆ°outputæ–‡ä»¶å¤¹"
        error_msg = f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"
        yield (error_detailed_status, error_chapter_info, {"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": 0, "ç”Ÿæˆè¿›åº¦": "é”™è¯¯", "å½“å‰å­—æ•°": 0}, error_msg, error_process_info, None, None)
        raise gr.Error(str(e))

def generate_outline_with_progress(prompt, num_chapters, writing_style, provider_name, model_name):
    """å¸¦è¿›åº¦æ˜¾ç¤ºçš„å°è¯´å¤§çº²ç”Ÿæˆå‡½æ•°"""
    try:
        if not prompt or not writing_style:
            raise gr.Error("æç¤ºè¯å’Œå†™ä½œé£æ ¼æ˜¯å¿…å¡«é¡¹")
        if num_chapters < 1:
            raise gr.Error("ç« èŠ‚æ•°å¿…é¡»å¤§äºç­‰äº1")
        
        # æ£€æŸ¥æä¾›å•†é…ç½®
        if not check_providers():
            raise gr.Error("è¯·å…ˆåœ¨é…ç½®é¡µé¢è®¾ç½®è‡³å°‘ä¸€ä¸ªAIæä¾›å•†çš„APIå¯†é’¥")

        num_chapters = int(num_chapters)
        
        # è½¬æ¢æä¾›å•†æ˜¾ç¤ºåç§°ä¸ºå†…éƒ¨é”®
        provider_map = {
            'DeepSeek': 'deepseek',
            'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
            'æ™ºè°±AI GLM': 'zhipu',
            'Google Gemini': 'gemini',
            'OpenRouter': 'openrouter',
            'LM Studio': 'lmstudio',
            'Claude': 'claude',
            'Grok': 'grok'
        }
        provider_key = provider_map.get(provider_name, provider_name.lower())
        
        # æ›´æ–°çŠ¶æ€æ  - å¼€å§‹ç”Ÿæˆ
        start_time = datetime.datetime.now()
        detailed_status = f"ğŸ”„ æ­£åœ¨ç”Ÿæˆå¤§çº²...\n\nğŸ“Š å½“å‰è¿›åº¦: å¼€å§‹ç”Ÿæˆ\nğŸ“š è®¡åˆ’ç« èŠ‚: {num_chapters}ç« \nğŸ¤– AIæä¾›å•†: {provider_name}\nğŸ¯ ä½¿ç”¨æ¨¡å‹: {model_name}\nğŸ’¡ å½“å‰æ­¥éª¤: å¤§çº²ç”Ÿæˆä¸­\nğŸ“‹ æ­¥éª¤æè¿°: æ­£åœ¨åˆ›å»ºå°è¯´å¤§çº²å’Œæ•…äº‹ç»“æ„"
        
        chapter_info = f"ğŸ“– å¤§çº²ç”Ÿæˆä¸­...\n\nğŸ“‹ è®¡åˆ’ç« èŠ‚æ•°: {num_chapters}\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}\nğŸ“ å½“å‰é˜¶æ®µ: å¤§çº²åˆ›å»º\nâ° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}"
        
        generation_stats = {"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": num_chapters, "ç”Ÿæˆè¿›åº¦": "å¤§çº²ç”Ÿæˆä¸­", "å½“å‰å­—æ•°": 0}
        
        log_msg = f"ğŸ¯ å¼€å§‹ç”Ÿæˆå¤§çº² - æä¾›å•†: {provider_name}, æ¨¡å‹: {model_name}"
        
        process_info = f"ğŸ” å¤§çº²ç”Ÿæˆè¿‡ç¨‹\n\nğŸ“Š å½“å‰æ­¥éª¤: å¤§çº²ç”Ÿæˆ\nâ° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}\n\nğŸ“‹ æ­£åœ¨ç”Ÿæˆå®Œæ•´çš„å°è¯´å¤§çº²..."
        
        # å…ˆyieldåˆå§‹çŠ¶æ€
        yield (
            "", 
            "", 
            "", 
            "", 
            "", 
            gr.update(visible=False),
            detailed_status,
            chapter_info,
            generation_stats,
            log_msg,
            process_info
        )
        
        # ä½¿ç”¨å¢å¼ºçš„å°è¯´åˆ›ä½œå™¨ç”Ÿæˆå¤§çº²
        writer = StoryWriter()
        
        # è®¾ç½®æä¾›å•†å’Œæ¨¡å‹
        if provider_key:
            writer.config_manager.provider_manager.switch_provider(provider_key)
        if model_name:
            writer.current_model = model_name
            
        logger.info(f"ğŸ¯ å¼€å§‹ç”Ÿæˆå¤§çº² - æä¾›å•†: {provider_name}, æ¨¡å‹: {model_name}")
        
        outline_data = writer.generate_complete_outline(prompt, num_chapters, writing_style)
        
        # éªŒè¯è¿”å›æ•°æ®
        required_keys = ["title", "plot", "character_list", "story_outline", "storyline"]
        for key in required_keys:
            if key not in outline_data:
                logger.error(f"âŒ å¤§çº²æ•°æ®ç¼ºå°‘å¿…è¦é”®: {key}")
                raise gr.Error(f"ç”Ÿæˆçš„å¤§çº²æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå°‘: {key}")
        
        logger.info(f"âœ… å¤§çº²ç”ŸæˆæˆåŠŸ - æ ‡é¢˜: {outline_data['title']}")
        
        # æ›´æ–°çŠ¶æ€æ  - å®Œæˆç”Ÿæˆ
        end_time = datetime.datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # ä¼°ç®—æ€»å­—æ•°
        total_outline_words = len(outline_data["plot"]) + len(outline_data["character_list"]) + len(outline_data["story_outline"]) + len(outline_data["storyline"])
        
        success_detailed_status = f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆ!\n\nğŸ“Š ç”Ÿæˆè¿›åº¦: 100% å®Œæˆ\nğŸ“š è®¡åˆ’ç« èŠ‚: {num_chapters}ç« \nğŸ¤– AIæä¾›å•†: {provider_name}\nğŸ¯ ä½¿ç”¨æ¨¡å‹: {model_name}\nğŸ’¡ å½“å‰æ­¥éª¤: å¤§çº²ç”Ÿæˆå®Œæˆ\nğŸ“‹ å°è¯´æ ‡é¢˜: {outline_data['title']}\nğŸ”¢ å¤§çº²å­—æ•°: {total_outline_words:,}å­—\nâ±ï¸ ç”Ÿæˆè€—æ—¶: {duration:.2f}ç§’"
        
        success_chapter_info = f"ğŸ“– å¤§çº²ç”ŸæˆæˆåŠŸ!\n\nâœ… å°è¯´æ ‡é¢˜: {outline_data['title']}\nğŸ“‹ è®¡åˆ’ç« èŠ‚: {num_chapters}ç« \nğŸ”¢ å¤§çº²æ€»å­—æ•°: {total_outline_words:,}å­—\nâ±ï¸ ç”Ÿæˆè€—æ—¶: {duration:.2f}ç§’\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}\n\nğŸ“š ç°åœ¨å¯ä»¥å¼€å§‹åˆ›ä½œå°è¯´äº†!"
        
        success_stats = {"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": num_chapters, "ç”Ÿæˆè¿›åº¦": "å¤§çº²å®Œæˆ", "å½“å‰å­—æ•°": total_outline_words}
        
        success_log = f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆ - æ ‡é¢˜: {outline_data['title'][:50]}{'...' if len(outline_data['title']) > 50 else ''}, è€—æ—¶: {duration:.2f}ç§’"
        
        success_process_info = f"ğŸ” å¤§çº²ç”Ÿæˆå®Œæˆ\n\nğŸ“Š æœ€ç»ˆçŠ¶æ€: æˆåŠŸå®Œæˆ\nâ° å®Œæˆæ—¶é—´: {end_time.strftime('%H:%M:%S')}\nâ±ï¸ æ€»è€—æ—¶: {duration:.2f}ç§’\n\nğŸ“‹ ç”Ÿæˆå†…å®¹:\nâ€¢ å°è¯´æ ‡é¢˜: {outline_data['title']}\nâ€¢ æƒ…èŠ‚æ¢—æ¦‚: {len(outline_data['plot'])}å­—\nâ€¢ äººç‰©åˆ—è¡¨: {len(outline_data['character_list'])}å­—\nâ€¢ æ•…äº‹å¤§çº²: {len(outline_data['story_outline'])}å­—\nâ€¢ è¯¦ç»†æ•…äº‹çº¿: {len(outline_data['storyline'])}å­—\n\nâœ… å¤§çº²åˆ›å»ºæˆåŠŸï¼Œå¯ä»¥å¼€å§‹åˆ›ä½œå°è¯´!"
        
        yield (
            outline_data["title"],
            outline_data["plot"], 
            outline_data["character_list"],
            outline_data["story_outline"],
            outline_data["storyline"],
            gr.update(visible=True),  # æ˜¾ç¤ºå¼€å§‹åˆ›ä½œæŒ‰é’®
            success_detailed_status,
            success_chapter_info,
            success_stats,
            success_log,
            success_process_info
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
        
        # æ›´æ–°çŠ¶æ€æ  - é”™è¯¯çŠ¶æ€
        error_detailed_status = f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥!\n\nğŸ“Š ç”Ÿæˆè¿›åº¦: é”™è¯¯\nğŸ“š è®¡åˆ’ç« èŠ‚: {num_chapters}ç« \nğŸ¤– AIæä¾›å•†: {provider_name}\nğŸ¯ ä½¿ç”¨æ¨¡å‹: {model_name}\nğŸ’¡ å½“å‰æ­¥éª¤: ç”Ÿæˆå¤±è´¥\nğŸ“‹ é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...\nâš ï¸ çŠ¶æ€: å¤§çº²ç”Ÿæˆå¤±è´¥"
        
        error_chapter_info = f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥!\n\nğŸš« é”™è¯¯ç±»å‹: å¤§çº²ç”Ÿæˆå¼‚å¸¸\nğŸ“ é”™è¯¯è¯¦æƒ…: {str(e)[:150]}...\nğŸ”„ å»ºè®®: è¯·æ£€æŸ¥é…ç½®åé‡è¯•\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}"
        
        error_stats = {"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": 0, "ç”Ÿæˆè¿›åº¦": "é”™è¯¯", "å½“å‰å­—æ•°": 0}
        
        error_log = f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}"
        
        error_process_info = f"ğŸ” å¤§çº²ç”Ÿæˆå¤±è´¥\n\nâŒ é”™è¯¯å‘ç”Ÿ\nâ° æ—¶é—´: {datetime.datetime.now().strftime('%H:%M:%S')}\nğŸš« é”™è¯¯ä¿¡æ¯: {str(e)[:100]}...\nğŸ¯ æä¾›å•†: {provider_name}\nğŸ¤– æ¨¡å‹: {model_name}\n\nğŸ”„ è¯·æ£€æŸ¥é…ç½®åé‡è¯•"
        
        # è¿”å›ç©ºå€¼å’Œéšè—æŒ‰é’®ï¼ŒåŒæ—¶æ›´æ–°çŠ¶æ€æ 
        yield (
            "", 
            "", 
            "", 
            "", 
            "", 
            gr.update(visible=False),
            error_detailed_status,
            error_chapter_info,
            error_stats,
            error_log,
            error_process_info
        )

def generate_novel_from_outline(title, plot, character_list, story_outline, storyline, 
                               num_chapters, writing_style, provider_name, model_name):
    """åŸºäºå¤§çº²ç”Ÿæˆå°è¯´ï¼ˆå¸¦è¿›åº¦è¿½è¸ªï¼‰"""
    logger.info(f"ğŸ“ å¼€å§‹åŸºäºå¤§çº²ç”Ÿæˆå°è¯´ï¼š{title}")
    
    # æ„å»ºå¤§çº²æ•°æ®
    outline_data = {
        "title": title,
        "plot": plot,
        "character_list": character_list,
        "story_outline": story_outline,
        "storyline": storyline
    }
    
    # è½¬æ¢æä¾›å•†æ˜¾ç¤ºåç§°ä¸ºå†…éƒ¨é”®
    provider_map = {
        'DeepSeek': 'deepseek',
        'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
        'æ™ºè°±AI GLM': 'zhipu',
        'Google Gemini': 'gemini',
        'OpenRouter': 'openrouter',
        'LM Studio': 'lmstudio',
        'Claude': 'claude',
        'Grok': 'grok'
    }
    provider_key = provider_map.get(provider_name, provider_name.lower())
    
    # è¿›åº¦è¿½è¸ªå˜é‡
    current_step = 0
    total_steps = num_chapters + 3  # ç« èŠ‚æ•° + åˆå§‹åŒ– + ä¿å­˜ + ç”ŸæˆEPUB
    completed_chapters = []
    total_words = 0
    
    def progress_callback(step_name, current_chapter=None, chapter_content=None, is_completed=False):
        nonlocal current_step, completed_chapters, total_words
        
        if is_completed:
            current_step += 1
            if chapter_content:
                completed_chapters.append(current_chapter)
                total_words += len(chapter_content)
        
        # è®¡ç®—è¿›åº¦
        progress = int((current_step / total_steps) * 100)
        
        # æ›´æ–°è¯¦ç»†ç”ŸæˆçŠ¶æ€
        status_lines = [
            f"ğŸ”„ å°è¯´ç”Ÿæˆè¿›åº¦: {progress}% ({current_step}/{total_steps})",
            f"ğŸ“š å½“å‰æ­¥éª¤: {step_name}",
            f"ğŸ“ å·²å®Œæˆç« èŠ‚: {len(completed_chapters)}/{num_chapters}",
            f"ğŸ“Š å½“å‰å­—æ•°: {total_words:,}å­—"
        ]
        
        if current_chapter:
            status_lines.append(f"âœï¸ æ­£åœ¨å¤„ç†: {current_chapter}")
        
        generation_status_text = "\n".join(status_lines)
        
        # æ›´æ–°ç« èŠ‚è¿›åº¦
        if completed_chapters:
            chapter_progress_text = f"âœ… å·²å®Œæˆç« èŠ‚ ({len(completed_chapters)}/{num_chapters}):\n"
            for i, chapter in enumerate(completed_chapters[-10:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10ç« 
                chapter_progress_text += f"{i}. {chapter}\n"
            if len(completed_chapters) > 10:
                chapter_progress_text += f"... åŠå…¶ä»– {len(completed_chapters) - 10} ç« \n"
        else:
            chapter_progress_text = "ğŸ“ æ­£åœ¨å‡†å¤‡ç« èŠ‚åˆ›ä½œ..."
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "å·²ç”Ÿæˆç« èŠ‚": len(completed_chapters),
            "é¢„è®¡æ€»ç« èŠ‚": num_chapters,
            "ç”Ÿæˆè¿›åº¦": f"{progress}%",
            "å½“å‰å­—æ•°": total_words,
            "å½“å‰æ­¥éª¤": step_name
        }
        
        return generation_status_text, chapter_progress_text, stats
    
    # åˆå§‹åŒ–çŠ¶æ€
    status_text, progress_text, stats = progress_callback("åˆå§‹åŒ–å°è¯´ç”Ÿæˆå™¨...")
    
    try:
        # ä½¿ç”¨å¢å¼ºçš„å°è¯´åˆ›ä½œå™¨
        writer = StoryWriter()
        
        # æ·»åŠ è¿›åº¦å›è°ƒåˆ°å†™ä½œå™¨
        def chapter_progress_callback(chapter_index, chapter_title, chapter_content):
            return progress_callback(
                f"æ­£åœ¨åˆ›ä½œç¬¬{chapter_index + 1}ç« ",
                chapter_title,
                chapter_content,
                is_completed=True
            )
        
        # ä¿®æ”¹å†™ä½œå™¨ä»¥æ”¯æŒè¿›åº¦å›è°ƒ
        progress_callback("æ­£åœ¨ç”Ÿæˆç« èŠ‚å†…å®¹...")
        _, title, chapters, chapter_titles, chapter_tokens_list = writer.write_novel_from_outline(
            outline_data, num_chapters, writing_style, provider_key, model_name
        )
        
        # æ¨¡æ‹Ÿç« èŠ‚å®Œæˆè¿›åº¦ï¼ˆå› ä¸ºwrite_novel_from_outlineä¸ç›´æ¥æ”¯æŒå›è°ƒï¼‰
        for i, chapter in enumerate(chapters):
            # å®‰å…¨åœ°è·å–ç« èŠ‚æ ‡é¢˜
            try:
                if isinstance(chapter_titles[i], dict):
                    chapter_title = list(chapter_titles[i].keys())[0]
                elif isinstance(chapter_titles[i], str):
                    chapter_title = chapter_titles[i]
                else:
                    chapter_title = f"ç¬¬{i + 1}ç« "
            except (IndexError, KeyError, TypeError) as e:
                logger.warning(f"è·å–ç¬¬{i + 1}ç« æ ‡é¢˜å¤±è´¥: {e}")
                chapter_title = f"ç¬¬{i + 1}ç« "
            
            progress_callback(
                f"å®Œæˆç¬¬{i + 1}ç« åˆ›ä½œ",
                chapter_title,
                chapter,
                is_completed=True
            )
        
        # ç”¨chapter_titlesä¸­çš„æ­£æ–‡å–ä»£ç« èŠ‚è¯´æ˜
        for i, chapter in enumerate(chapters):
            try:
                if isinstance(chapter_titles[i], dict):
                    chapter_number_and_title = list(chapter_titles[i].keys())[0]
                    chapter_titles[i] = {chapter_number_and_title: chapter}
                elif isinstance(chapter_titles[i], str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œåˆ›å»ºå­—å…¸ç»“æ„
                    chapter_titles[i] = {chapter_titles[i]: chapter}
                else:
                    # åˆ›å»ºé»˜è®¤ç»“æ„
                    chapter_titles[i] = {f"ç¬¬{i + 1}ç« ": chapter}
            except (IndexError, KeyError, TypeError) as e:
                logger.warning(f"å¤„ç†ç¬¬{i + 1}ç« æ ‡é¢˜å¤±è´¥: {e}")
                chapter_titles[i] = {f"ç¬¬{i + 1}ç« ": chapter}
        
        progress_callback("æ­£åœ¨ç”ŸæˆEPUBæ–‡ä»¶...")
        
        # æš‚æ—¶è·³è¿‡å°é¢ç”Ÿæˆï¼ˆåŠŸèƒ½ä¿ç•™ï¼Œä»¥åå®Œå–„ï¼‰
        image_url = None
        logger.info("å°é¢ç”ŸæˆåŠŸèƒ½å·²æš‚æ—¶ç¦ç”¨")
        
        # ç”Ÿæˆå°è¯´ EPUB æ–‡ä»¶ï¼ˆä¸ä½¿ç”¨å°é¢ï¼‰
        file_url = create_epub(title, 'AI', chapter_titles, cover_image_path=None)
        logger.info(f"Novel URL: {file_url}")
        
        # ä¿å­˜åˆ°outputæ–‡ä»¶å¤¹
        progress_callback("æ­£åœ¨ä¿å­˜å°è¯´æ–‡ä»¶...")
        novel_id = f"outline_{int(time.time())}"
        save_novel_to_output(title, chapters, chapter_titles, provider_name, model_name, total_words, novel_id)
        
        # æœ€ç»ˆçŠ¶æ€æ›´æ–°
        final_status, final_progress, final_stats = progress_callback("âœ… å°è¯´ç”Ÿæˆå®Œæˆï¼", is_completed=True)
        
        logger.info(f"âœ… å°è¯´ã€Š{title}ã€‹ç”Ÿæˆå®Œæˆï¼Œå…±{len(chapters)}ç« ï¼Œ{total_words:,}å­—")
        
        return (
            image_url,
            file_url,
            final_status,
            final_progress,
            final_stats
        )
        
    except Exception as e:
        error_message = f"âŒ å°è¯´ç”Ÿæˆå¤±è´¥: {str(e)}"
        logger.error(error_message)
        return (
            None,
            None,
            error_message,
            "ç”Ÿæˆå¤±è´¥",
            {"é”™è¯¯": str(e)}
        )

def generate_output(prompt, num_chapters, writing_style, provider_name, model_name):
    """å…¼å®¹åŸç‰ˆçš„ç”Ÿæˆå‡½æ•°"""
    try:
        output = generate_novel(prompt, num_chapters, writing_style, provider_name, model_name)
        return (output["image_url"], output["file_url"])
    except Exception as e:
        raise gr.Error(str(e))


def get_default_values():
    """è·å–é»˜è®¤å€¼"""
    if config_manager.default_ideas_config.enabled:
        return (
            config_manager.default_ideas_config.default_idea or "ä¸€ä¸ªè¢«é—å¿˜çš„å°å²›ï¼Œä¸Šé¢æœ‰ä¸€åº§å¤è€çš„ç¯å¡”ã€‚å½“ç¯å¡”äº®èµ·æ—¶ï¼Œå²›ä¸Šçš„ç”Ÿç‰©å°±ä¼šå‘ç”Ÿå¥‡å¼‚çš„å˜åŒ–ã€‚",
            config_manager.default_ideas_config.default_writing_style or "ç´§å¼ åˆºæ¿€ï¼Œç±»ä¼¼äºé’å°‘å¹´ææ€–å°è¯´ã€‚æœ‰å¾ˆå¤šå¯¹è¯å’Œå†…å¿ƒç‹¬ç™½"
        )
    return (
        "ä¸€ä¸ªè¢«é—å¿˜çš„å°å²›ï¼Œä¸Šé¢æœ‰ä¸€åº§å¤è€çš„ç¯å¡”ã€‚å½“ç¯å¡”äº®èµ·æ—¶ï¼Œå²›ä¸Šçš„ç”Ÿç‰©å°±ä¼šå‘ç”Ÿå¥‡å¼‚çš„å˜åŒ–ã€‚",
        "ç´§å¼ åˆºæ¿€ï¼Œç±»ä¼¼äºé’å°‘å¹´ææ€–å°è¯´ã€‚æœ‰å¾ˆå¤šå¯¹è¯å’Œå†…å¿ƒç‹¬ç™½"
    )

def get_available_providers():
    """è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨ï¼ˆåªæ˜¾ç¤ºæœ‰APIå¯†é’¥çš„ï¼‰"""
    provider_names = {
        'deepseek': 'DeepSeek',
        'alicloud': 'é˜¿é‡Œäº‘é€šä¹‰åƒé—®',
        'zhipu': 'æ™ºè°±AI GLM',
        'gemini': 'Google Gemini',
        'openrouter': 'OpenRouter',
        'lmstudio': 'LM Studio',
        'claude': 'Claude',
        'grok': 'Grok'
    }
    
    # è·å–æä¾›å•†çŠ¶æ€ï¼Œåªè¿”å›æœ‰APIå¯†é’¥çš„
    status = config_manager.provider_manager.get_provider_status()
    available_keys = [key for key, data in status.items() if data.get('api_key_set', False)]
    available_names = [provider_names[key] for key in available_keys if key in provider_names]
    
    # å¦‚æœæ²¡æœ‰å¯ç”¨æä¾›å•†ï¼Œè¿”å›æ‰€æœ‰æä¾›å•†ï¼ˆç”¨äºåˆå§‹åŒ–ï¼‰
    if not available_names:
        available_names = list(provider_names.values())
    
    # é€‰æ‹©é»˜è®¤æä¾›å•†
    current_provider = config_manager.provider_manager.get_current_provider_name()
    default_provider = provider_names.get(current_provider, 'DeepSeek')
    if default_provider not in available_names and available_names:
        default_provider = available_names[0]
    
    return available_names, default_provider

def get_models_for_current_provider():
    """è·å–å½“å‰æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨å’Œé»˜è®¤æ¨¡å‹"""
    try:
        # è·å–å®é™…å¯ç”¨çš„æä¾›å•†ï¼Œè€Œä¸æ˜¯é…ç½®ä¸­çš„å½“å‰æä¾›å•†
        available_providers, current_provider_display = get_available_providers()
        
        # è½¬æ¢æ˜¾ç¤ºåç§°ä¸ºé”®
        provider_map = {
            'DeepSeek': 'deepseek',
            'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
            'æ™ºè°±AI GLM': 'zhipu',
            'Google Gemini': 'gemini',
            'OpenRouter': 'openrouter',
            'LM Studio': 'lmstudio',
            'Claude': 'claude',
            'Grok': 'grok'
        }
        
        current_provider_key = provider_map.get(current_provider_display, 'deepseek')
        models = config_manager.provider_manager.get_models_for_provider(current_provider_key)
        if models:
            # è·å–é»˜è®¤æ¨¡å‹
            default_model = config_manager.provider_manager.get_default_model(current_provider_key)
            # å¦‚æœé»˜è®¤æ¨¡å‹å­˜åœ¨ä¸”åœ¨æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹
            selected_model = default_model if default_model in models else models[0]
            return models, selected_model
        return ["é»˜è®¤æ¨¡å‹"], "é»˜è®¤æ¨¡å‹"
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return ["é»˜è®¤æ¨¡å‹"], "é»˜è®¤æ¨¡å‹"

default_idea, default_style = get_default_values()
available_providers, current_provider = get_available_providers()
available_models, selected_model = get_models_for_current_provider()

version_info = get_version_info()
app_title = f"ğŸ­ StoryGeniusï¼šAIæ™ºèƒ½å°è¯´åˆ›ä½œå¹³å° v{get_version()}"
app_description = f"""
### ğŸŒŸ æ¬¢è¿ä½¿ç”¨StoryGenius AIå°è¯´åˆ›ä½œå¹³å°

**ç‰ˆæœ¬**: {version_info['version']} ({version_info['codename']}) | **å‘å¸ƒæ—¥æœŸ**: {version_info['release_date']}

æ”¯æŒ8ä¸ªAIæä¾›å•†ï¼š**DeepSeek** | **é˜¿é‡Œäº‘** | **æ™ºè°±AI** | **Google Gemini** | **OpenRouter** | **LM Studio** | **Claude** | **Grok**

ğŸ“ **åŠŸèƒ½ç‰¹è‰²ï¼š**
- ğŸ¤– å¤šAIæä¾›å•†æ™ºèƒ½åˆ‡æ¢
- ğŸ“Š å®æ—¶æˆæœ¬ç›‘æ§ä¸æ€§èƒ½è¿½è¸ª  
- ğŸ¨ è‡ªåŠ¨ç”Ÿæˆç²¾ç¾å°é¢
- ğŸ“š ä¸€é”®å¯¼å‡ºEPUBç”µå­ä¹¦
- âš™ï¸ ä¸ªæ€§åŒ–é…ç½®ç®¡ç†

ğŸ’¡ **ä½¿ç”¨æç¤ºï¼š** é¦–æ¬¡ä½¿ç”¨è¯·å…ˆåˆ°"é…ç½®ç®¡ç†"é¡µé¢è®¾ç½®AIæä¾›å•†çš„APIå¯†é’¥
"""


def update_models_dropdown(provider_name):
    """æ ¹æ®æä¾›å•†æ›´æ–°æ¨¡å‹ä¸‹æ‹‰åˆ—è¡¨"""
    try:
        # è½¬æ¢æ˜¾ç¤ºåç§°ä¸ºé”®
        provider_map = {
            'DeepSeek': 'deepseek',
            'é˜¿é‡Œäº‘é€šä¹‰åƒé—®': 'alicloud', 
            'æ™ºè°±AI GLM': 'zhipu',
            'Google Gemini': 'gemini',
            'OpenRouter': 'openrouter',
            'LM Studio': 'lmstudio',
            'Claude': 'claude',
            'Grok': 'grok'
        }
        
        provider_key = provider_map.get(provider_name)
        if provider_key:
            models = config_manager.provider_manager.get_models_for_provider(provider_key)
            if models:
                # è·å–é»˜è®¤æ¨¡å‹
                default_model = config_manager.provider_manager.get_default_model(provider_key)
                # å¦‚æœé»˜è®¤æ¨¡å‹å­˜åœ¨ä¸”åœ¨æ¨¡å‹åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼›å¦åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹
                selected_model = default_model if default_model in models else models[0]
                return gr.update(choices=models, value=selected_model)
        
        return gr.update(choices=["é»˜è®¤æ¨¡å‹"], value="é»˜è®¤æ¨¡å‹")
    except Exception as e:
        logger.error(f"æ›´æ–°æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return gr.update(choices=["é»˜è®¤æ¨¡å‹"], value="é»˜è®¤æ¨¡å‹")

def refresh_providers_and_status():
    """åˆ·æ–°æä¾›å•†åˆ—è¡¨å’ŒçŠ¶æ€"""
    try:
        available_providers, current_provider = get_available_providers()
        status_text = get_provider_status()
        
        # è·å–å½“å‰æä¾›å•†çš„æ¨¡å‹ï¼ˆä½¿ç”¨æ­£ç¡®çš„é»˜è®¤æ¨¡å‹ï¼‰
        if available_providers:
            # ä½¿ç”¨å½“å‰æä¾›å•†è€Œä¸æ˜¯ç¬¬ä¸€ä¸ªå¯ç”¨æä¾›å•†
            provider_to_use = current_provider if current_provider in available_providers else available_providers[0]
            models = update_models_dropdown(provider_to_use)
            return (
                gr.update(choices=available_providers, value=provider_to_use),
                models,
                status_text
            )
        else:
            return (
                gr.update(choices=["è¯·å…ˆé…ç½®æä¾›å•†"], value="è¯·å…ˆé…ç½®æä¾›å•†"),
                gr.update(choices=["é»˜è®¤æ¨¡å‹"], value="é»˜è®¤æ¨¡å‹"),
                status_text
            )
    except Exception as e:
        logger.error(f"åˆ·æ–°æä¾›å•†åˆ—è¡¨å¤±è´¥: {e}")
        return (
            gr.update(choices=["é…ç½®é”™è¯¯"], value="é…ç½®é”™è¯¯"),
            gr.update(choices=["é»˜è®¤æ¨¡å‹"], value="é»˜è®¤æ¨¡å‹"),
            "è·å–çŠ¶æ€å¤±è´¥"
        )

def get_provider_status():
    """è·å–æä¾›å•†çŠ¶æ€"""
    try:
        status = config_manager.provider_manager.get_provider_status()
        status_text = "## ğŸ”§ AIæä¾›å•†çŠ¶æ€\n\n"
        
        for provider, data in status.items():
            provider_names = {
                'deepseek': 'DeepSeek',
                'alicloud': 'é˜¿é‡Œäº‘é€šä¹‰åƒé—®',
                'zhipu': 'æ™ºè°±AI GLM', 
                'gemini': 'Google Gemini',
                'openrouter': 'OpenRouter',
                'lmstudio': 'LM Studio',
                'claude': 'Claude',
                'grok': 'Grok'
            }
            
            name = provider_names.get(provider, provider)
            conn_status = "âœ… å·²è¿æ¥" if data.get('connected', False) else "âŒ æœªè¿æ¥"
            api_status = "âœ… å·²è®¾ç½®" if data.get('api_key_set', False) else "âŒ æœªè®¾ç½®"
            models_count = data.get('models_count', 0)
            
            status_text += f"**{name}:** {conn_status} | APIå¯†é’¥: {api_status} | æ¨¡å‹æ•°: {models_count}\n\n"
        
        return status_text
    except Exception as e:
        return f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"

# åˆ›å»ºä¸»ç•Œé¢
with gr.Blocks(
    title=app_title,
    theme=gr.themes.Soft(),
    css="""
    .gradio-container {
        max-width: 1200px !important;
    }
    .main-header {
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    """
) as app:
    gr.Markdown(f"# {app_title}")
    gr.Markdown(app_description)
    
    with gr.Tabs() as tabs:
        # ä¸»åˆ›ä½œç•Œé¢
        with gr.Tab("ğŸ“ å°è¯´åˆ›ä½œ", id="main"):
            with gr.Row():
                with gr.Column(scale=2):
                    # è¾“å…¥åŒºåŸŸ
                    prompt_input = gr.Textbox(
                        value=default_idea, 
                        lines=3, 
                        placeholder="è¯·è¾“å…¥å°è¯´åˆ›æ„...", 
                        label="ğŸ’¡ å°è¯´æç¤ºè¯"
                    )
                    chapters_input = gr.Number(
                        value=20, 
                        minimum=1, 
                        maximum=500, 
                        label="ğŸ“š å°è¯´ç« èŠ‚æ•°"
                    )
                    style_input = gr.Textbox(
                        value=default_style, 
                        lines=3, 
                        placeholder="æè¿°æ‚¨æƒ³è¦çš„å†™ä½œé£æ ¼...", 
                        label="âœï¸ AIå†™ä½œé£æ ¼"
                    )
                    
                    with gr.Row():
                        provider_input = gr.Dropdown(
                            choices=available_providers,
                            value=current_provider,
                            label="ğŸ¤– é€‰æ‹©AIæä¾›å•†",
                            interactive=True
                        )
                        model_input = gr.Dropdown(
                            choices=available_models,
                            value=selected_model,
                            label="ğŸ¯ é€‰æ‹©æ¨¡å‹",
                            interactive=True
                        )
                    
                    # æä¾›å•†å˜æ›´æ—¶æ›´æ–°æ¨¡å‹åˆ—è¡¨
                    provider_input.change(
                        update_models_dropdown,
                        inputs=[provider_input],
                        outputs=[model_input]
                    )
                    
                    # é¡µé¢åŠ è½½æ—¶åˆ·æ–°æ¨¡å‹åˆ—è¡¨ä»¥ç¡®ä¿æ˜¾ç¤ºæ­£ç¡®çš„é»˜è®¤æ¨¡å‹
                    def refresh_model_on_load():
                        """é¡µé¢åŠ è½½æ—¶åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
                        try:
                            # ä½¿ç”¨å®é™…å¯ç”¨çš„æä¾›å•†ï¼Œè€Œä¸æ˜¯é…ç½®ä¸­çš„å½“å‰æä¾›å•†
                            available_providers, current_provider_display = get_available_providers()
                            return update_models_dropdown(current_provider_display)
                        except Exception as e:
                            logger.error(f"åˆ·æ–°æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
                            return gr.update(choices=["é»˜è®¤æ¨¡å‹"], value="é»˜è®¤æ¨¡å‹")
                    
                    # é¡µé¢åŠ è½½æ—¶è‡ªåŠ¨åˆ·æ–°
                    app.load(refresh_model_on_load, outputs=[model_input])
                    
                    # ç”ŸæˆæŒ‰é’®
                    with gr.Row():
                        generate_outline_btn = gr.Button(
                            "ğŸ“‹ ç”Ÿæˆå¤§çº²", 
                            variant="secondary", 
                            size="lg"
                        )
                        generate_novel_btn = gr.Button(
                            "ğŸš€ å¼€å§‹åˆ›ä½œå°è¯´", 
                            variant="primary", 
                            size="lg",
                            visible=False
                        )
                
                with gr.Column(scale=1):
                    # çŠ¶æ€æ˜¾ç¤º
                    with gr.Group():
                        gr.Markdown("### ğŸ“Š ç³»ç»ŸçŠ¶æ€")
                        status_display = gr.Markdown(
                            value=get_provider_status(),
                            every=10  # æ¯10ç§’æ›´æ–°
                        )
                        
                        refresh_status_btn = gr.Button(
                            "ğŸ”„ åˆ·æ–°æä¾›å•†", 
                            variant="secondary"
                        )
            
            # å¤§çº²é¢„è§ˆåŒºåŸŸ
            with gr.Group(visible=False) as outline_preview:
                gr.Markdown("## ğŸ“‹ å¤§çº²é¢„è§ˆ")
                with gr.Row():
                    with gr.Column(scale=1):
                        title_preview = gr.Textbox(
                            label="ğŸ“š å°è¯´æ ‡é¢˜",
                            interactive=False,
                            lines=3
                        )
                        plot_preview = gr.Textbox(
                            label="ğŸ“– æƒ…èŠ‚æ¢—æ¦‚",
                            interactive=False,
                            lines=10
                        )
                    with gr.Column(scale=1):
                        character_preview = gr.Textbox(
                            label="ğŸ‘¥ äººç‰©åˆ—è¡¨",
                            interactive=False,
                            lines=12
                        )
                
                with gr.Row():
                    story_outline_preview = gr.Textbox(
                        label="ğŸ“‹ æ•…äº‹å¤§çº²",
                        interactive=False,
                        lines=10,
                        max_lines=20
                    )
                    storyline_preview = gr.Textbox(
                        label="ğŸ“ è¯¦ç»†æ•…äº‹çº¿",
                        interactive=False,
                        lines=10,
                        max_lines=20
                    )
            
            # è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
            with gr.Row():
                with gr.Column(scale=2):
                    # è¯¦ç»†çš„ç”ŸæˆçŠ¶æ€ä¿¡æ¯
                    generation_status = gr.Textbox(
                        label="ğŸ“‹ è¯¦ç»†ç”ŸæˆçŠ¶æ€",
                        value="ğŸ”„ ç­‰å¾…å¼€å§‹å°è¯´åˆ›ä½œ...\n\nğŸ“Š å½“å‰è¿›åº¦: 0%\nğŸ“š ç« èŠ‚çŠ¶æ€: æœªå¼€å§‹\nğŸ”¢ å­—æ•°ç»Ÿè®¡: 0å­—\nğŸ’¡ å½“å‰æ­¥éª¤: å‡†å¤‡ä¸­",
                        interactive=False,
                        lines=8,
                        max_lines=12
                    )
                    
                with gr.Column(scale=1):
                    # ç« èŠ‚å®Œæˆæƒ…å†µ
                    chapter_progress = gr.Textbox(
                        label="ğŸ“– ç« èŠ‚å®Œæˆæƒ…å†µ",
                        value="æš‚æ— ç« èŠ‚å®Œæˆ",
                        interactive=False,
                        lines=8,
                        max_lines=12
                    )
                    
                    # ä¿ç•™ä¸€ä¸ªç®€åŒ–çš„ç»Ÿè®¡JSONï¼ˆéšè—ï¼‰
                    generation_stats = gr.JSON(
                        label="ğŸ“Š ç”Ÿæˆç»Ÿè®¡",
                        value={"å·²ç”Ÿæˆç« èŠ‚": 0, "é¢„è®¡æ€»ç« èŠ‚": 0, "ç”Ÿæˆè¿›åº¦": "0%", "å½“å‰å­—æ•°": 0},
                        visible=False
                    )
                    
            
            # å®æ—¶æ—¥å¿—å’Œç”Ÿæˆè¿‡ç¨‹æ˜¾ç¤º
            with gr.Row():
                with gr.Column(scale=1):
                    generation_log = gr.Textbox(
                        label="ğŸ“ ç”Ÿæˆæ—¥å¿—",
                        value="",
                        interactive=False,
                        lines=6,
                        max_lines=10
                    )
                
                with gr.Column(scale=1):
                    generation_process = gr.Textbox(
                        label="ğŸ” ç”Ÿæˆè¿‡ç¨‹è¯¦æƒ…",
                        value="æš‚æ— ç”Ÿæˆè¿‡ç¨‹ä¿¡æ¯",
                        interactive=False,
                        lines=6,
                        max_lines=10
                    )
            
            # è¾“å‡ºåŒºåŸŸ
            with gr.Row():
                cover_output = gr.Image(label="ğŸ“– å°é¢å›¾ç‰‡", width=1028, height=300)
                file_output = gr.File(label="ğŸ“„ EPUBæ–‡ä»¶")
            
            # ç»‘å®šäº‹ä»¶
            generate_outline_btn.click(
                generate_outline_with_progress,
                inputs=[prompt_input, chapters_input, style_input, provider_input, model_input],
                outputs=[title_preview, plot_preview, character_preview, story_outline_preview, storyline_preview, generate_novel_btn, generation_status, chapter_progress, generation_stats, generation_log, generation_process]
            ).then(
                lambda: gr.update(visible=True),
                outputs=[outline_preview]
            )
            
            generate_novel_btn.click(
                generate_novel_from_outline,
                inputs=[title_preview, plot_preview, character_preview, story_outline_preview, storyline_preview, chapters_input, style_input, provider_input, model_input],
                outputs=[cover_output, file_output, generation_status, chapter_progress, generation_stats]
            )
            
            refresh_status_btn.click(
                refresh_providers_and_status,
                outputs=[provider_input, model_input, status_display]
            )
        
        # é…ç½®ç®¡ç†ç•Œé¢
        with gr.Tab("âš™ï¸ é…ç½®ç®¡ç†", id="config"):
            gr.Markdown("# ğŸ›ï¸ StoryGenius é…ç½®ç®¡ç†ä¸­å¿ƒ")
            
            # åˆ›å»ºå„ä¸ªé€‰é¡¹å¡
            with gr.Tabs():
                config_ui.create_provider_config_tab()
                config_ui.create_monitoring_tab()
                config_ui.create_default_ideas_tab()
                config_ui.create_openrouter_tab()
                
                # ç³»ç»Ÿé…ç½®é€‰é¡¹å¡
                with gr.Tab("âš™ï¸ ç³»ç»Ÿè®¾ç½®"):
                    gr.Markdown("## ç³»ç»Ÿé…ç½®")
                    
                    with gr.Row():
                        with gr.Column():
                            auto_save = gr.Checkbox(
                                label="è‡ªåŠ¨ä¿å­˜é…ç½®",
                                value=config_manager.system_config.auto_save
                            )
                            
                            cache_models = gr.Checkbox(
                                label="ç¼“å­˜æ¨¡å‹åˆ—è¡¨",
                                value=config_manager.system_config.cache_models
                            )
                            
                            debug_mode = gr.Checkbox(
                                label="è°ƒè¯•æ¨¡å¼",
                                value=config_manager.system_config.debug_mode
                            )
                        
                        with gr.Column():
                            max_retries = gr.Slider(
                                label="æœ€å¤§é‡è¯•æ¬¡æ•°",
                                minimum=1,
                                maximum=10,
                                value=config_manager.system_config.max_retries,
                                step=1
                            )
                            
                            timeout = gr.Slider(
                                label="è¶…æ—¶æ—¶é—´ (ç§’)",
                                minimum=10,
                                maximum=120,
                                value=config_manager.system_config.timeout,
                                step=5
                            )
                    
                    # é…ç½®ç®¡ç†æŒ‰é’®
                    with gr.Row():
                        export_config_btn = gr.Button("ğŸ“¤ å¯¼å‡ºé…ç½®", variant="secondary")
                        import_config_btn = gr.Button("ğŸ“¥ å¯¼å…¥é…ç½®", variant="secondary")
                        reset_all_btn = gr.Button("ğŸ”„ é‡ç½®æ‰€æœ‰é…ç½®", variant="secondary")
                    
                    # é…ç½®æ–‡ä»¶ä¸Šä¼ 
                    config_file_upload = gr.File(
                        label="é€‰æ‹©é…ç½®æ–‡ä»¶",
                        file_types=[".json"]
                    )
                    
                    system_status = gr.Textbox(
                        label="ç³»ç»ŸçŠ¶æ€",
                        value="",
                        interactive=False
                    )
                    
                    def save_system_settings(auto_save_val, cache_models_val, debug_mode_val, max_retries_val, timeout_val):
                        """ä¿å­˜ç³»ç»Ÿè®¾ç½®"""
                        try:
                            config_manager.system_config.auto_save = auto_save_val
                            config_manager.system_config.cache_models = cache_models_val
                            config_manager.system_config.debug_mode = debug_mode_val
                            config_manager.system_config.max_retries = int(max_retries_val)
                            config_manager.system_config.timeout = int(timeout_val)
                            config_manager.save_system_config()
                            return "âœ… ç³»ç»Ÿè®¾ç½®å·²ä¿å­˜"
                        except Exception as e:
                            return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"
                    
                    def export_config():
                        """å¯¼å‡ºé…ç½®"""
                        try:
                            export_path = f"config_backup_{int(time.time())}.json"
                            config_manager.export_config(export_path)
                            return f"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {export_path}"
                        except Exception as e:
                            return f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}"
                    
                    def import_config(file_path):
                        """å¯¼å…¥é…ç½®"""
                        try:
                            if file_path:
                                config_manager.import_config(file_path)
                                return "âœ… é…ç½®å·²å¯¼å…¥"
                            return "âŒ è¯·é€‰æ‹©é…ç½®æ–‡ä»¶"
                        except Exception as e:
                            return f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}"
                    
                    def reset_all_config():
                        """é‡ç½®æ‰€æœ‰é…ç½®"""
                        try:
                            config_manager.reset_config()
                            return "âœ… é…ç½®å·²é‡ç½®"
                        except Exception as e:
                            return f"âŒ é‡ç½®å¤±è´¥: {str(e)}"
                    
                    # ç»‘å®šäº‹ä»¶
                    for component in [auto_save, cache_models, debug_mode, max_retries, timeout]:
                        component.change(
                            save_system_settings,
                            inputs=[auto_save, cache_models, debug_mode, max_retries, timeout],
                            outputs=[system_status]
                        )
                    
                    export_config_btn.click(
                        export_config,
                        outputs=[system_status]
                    )
                    
                    import_config_btn.click(
                        import_config,
                        inputs=[config_file_upload],
                        outputs=[system_status]
                    )
                    
                    reset_all_btn.click(
                        reset_all_config,
                        outputs=[system_status]
                    )
        
        # ä½¿ç”¨è¯´æ˜
        with gr.Tab("ğŸ“– ä½¿ç”¨è¯´æ˜", id="help"):
            gr.Markdown("""
            # ğŸ“– StoryGenius ä½¿ç”¨æŒ‡å—
            
            ## ğŸš€ å¿«é€Ÿå¼€å§‹
            
            ### 1ï¸âƒ£ é…ç½®AIæä¾›å•†
            - å‰å¾€ **"âš™ï¸ é…ç½®ç®¡ç†"** é¡µé¢
            - é€‰æ‹©æ‚¨è¦ä½¿ç”¨çš„AIæä¾›å•†
            - è¾“å…¥å¯¹åº”çš„APIå¯†é’¥
            - ç‚¹å‡» **"æµ‹è¯•è¿æ¥"** ç¡®è®¤é…ç½®æˆåŠŸ
            
            ### 2ï¸âƒ£ åˆ›ä½œå°è¯´
            - è¿”å› **"ğŸ“ å°è¯´åˆ›ä½œ"** é¡µé¢
            - è¾“å…¥æ‚¨çš„å°è¯´åˆ›æ„
            - è®¾ç½®ç« èŠ‚æ•°é‡ï¼ˆå»ºè®®2-50ç« ï¼‰
            - æè¿°å†™ä½œé£æ ¼
            - é€‰æ‹©AIæä¾›å•†å’Œæ¨¡å‹
            - ç‚¹å‡» **"ğŸš€ å¼€å§‹åˆ›ä½œå°è¯´"**
            
            ## ğŸ¤– æ”¯æŒçš„AIæä¾›å•†
            
            | æä¾›å•† | ç‰¹ç‚¹ | æ¨èæ¨¡å‹ |
            |--------|------|----------|
            | **DeepSeek** | æ€§ä»·æ¯”é«˜ï¼Œä¸­æ–‡è¡¨ç°ä¼˜ç§€ | deepseek-chat |
            | **é˜¿é‡Œäº‘** | å›½äº§æ¨¡å‹ï¼Œç¨³å®šå¯é  | qwen-max |
            | **æ™ºè°±AI** | GLMç³»åˆ—ï¼Œåˆ›æ„å†™ä½œå¼º | glm-4 |
            | **Google Gemini** | å¤šæ¨¡æ€èƒ½åŠ›å¼º | gemini-pro |
            | **OpenRouter** | æ¨¡å‹é€‰æ‹©ä¸°å¯Œ | å„ç§å¼€æºæ¨¡å‹ |
            | **LM Studio** | æœ¬åœ°éƒ¨ç½²ï¼Œéšç§å®‰å…¨ | æœ¬åœ°æ¨¡å‹ |
            | **Claude** | é•¿æ–‡æœ¬å¤„ç†ä¼˜ç§€ | claude-3-sonnet |
            | **Grok** | å®æ—¶ä¿¡æ¯ï¼Œå¹½é»˜é£æ ¼ | grok-3-mini |
            
            ## ğŸ’¡ åˆ›ä½œæŠ€å·§
            
            ### æç¤ºè¯å»ºè®®
            - åŒ…å«å…·ä½“çš„è®¾å®šã€è§’è‰²ã€å†²çª
            - æä¾›è¶³å¤Ÿçš„èƒŒæ™¯ä¿¡æ¯
            - å¯ä»¥æŒ‡å®šé¢˜æï¼šå¥‡å¹»ã€ç§‘å¹»ã€æ‚¬ç–‘ç­‰
            
            ### å†™ä½œé£æ ¼æè¿°
            - æ˜ç¡®æ–‡é£ï¼šå¹½é»˜ã€ä¸¥è‚ƒã€è½»æ¾ç­‰
            - æŒ‡å®šç›®æ ‡è¯»è€…ï¼šé’å°‘å¹´ã€æˆäººç­‰
            - æåŠç‰¹æ®Šè¦æ±‚ï¼šå¯¹è¯å¤šã€æè¿°ç»†è…»ç­‰
            
            ## ğŸ“Š ç›‘æ§åŠŸèƒ½
            
            - **æˆæœ¬è¿½è¸ª**ï¼šå®æ—¶æ˜¾ç¤ºAPIè°ƒç”¨è´¹ç”¨
            - **æ€§èƒ½ç›‘æ§**ï¼šå“åº”æ—¶é—´å’ŒæˆåŠŸç‡ç»Ÿè®¡
            - **è°ƒç”¨è¯¦æƒ…**ï¼šå®Œæ•´çš„APIè¯·æ±‚è®°å½•
            
            ## âš ï¸ æ³¨æ„äº‹é¡¹
            
            - é¦–æ¬¡ä½¿ç”¨éœ€è¦é…ç½®APIå¯†é’¥
            - å»ºè®®ç« èŠ‚æ•°æ ¹æ®æˆæœ¬æ§åˆ¶ï¼Œé•¿ç¯‡å°è¯´å¯èƒ½äº§ç”Ÿè¾ƒé«˜è´¹ç”¨
            - ç”Ÿæˆè¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…
            - æ”¯æŒé…ç½®å¯¼å…¥/å¯¼å‡ºï¼Œä¾¿äºå¤‡ä»½
            
            ## ğŸ”§ æ•…éšœæ’é™¤
            
            ### å¸¸è§é—®é¢˜
            1. **è¿æ¥å¤±è´¥**ï¼šæ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥
            2. **ç”Ÿæˆä¸­æ–­**ï¼šæŸ¥çœ‹é”™è¯¯ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯é…é¢ä¸è¶³
            3. **æ¨¡å‹æ— æ³•åŠ è½½**ï¼šå°è¯•åˆ·æ–°æˆ–æ›´æ¢æä¾›å•†
            
            ### è·å–å¸®åŠ©
            - æŸ¥çœ‹è°ƒè¯•ä¿¡æ¯ï¼š"âš™ï¸ é…ç½®ç®¡ç†" â†’ "ğŸ“Š ç›‘æ§ä¸è°ƒè¯•" 
            - å¯¼å‡ºé…ç½®å¤‡ä»½ï¼š"âš™ï¸ é…ç½®ç®¡ç†" â†’ "âš™ï¸ ç³»ç»Ÿè®¾ç½®"
            """)

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    import socket
    
    # è·å–æœ¬æœºIPåœ°å€
    def get_local_ip():
        try:
            # è¿æ¥åˆ°å¤–éƒ¨åœ°å€ä»¥è·å–æœ¬æœºIP
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            local_ip = s.getsockname()[0]
            s.close()
            return local_ip
        except Exception:
            return "127.0.0.1"
    
    # æŸ¥æ‰¾å¯ç”¨ç«¯å£
    def find_available_port(start_port=8091):
        """æŸ¥æ‰¾å¯ç”¨çš„ç«¯å£"""
        for port in range(start_port, start_port + 100):  # å°è¯•100ä¸ªç«¯å£
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.bind(('localhost', port))
                    return port
            except OSError:
                continue
        return None
    
    local_ip = get_local_ip()
    port = find_available_port()
    
    if port is None:
        print("âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œè¯·æ‰‹åŠ¨æŒ‡å®šç«¯å£")
        exit(1)
    
    print(f"\nğŸš€ StoryGenius æ­£åœ¨å¯åŠ¨...")
    print(f"ğŸ“ æœ¬åœ°è®¿é—®: http://localhost:{port}")
    print(f"ğŸŒ å±€åŸŸç½‘è®¿é—®: http://{local_ip}:{port}")
    print(f"â¹ï¸  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")
    
    app.launch(
        server_name="0.0.0.0",
        server_port=port,
        share=False,
        show_error=True,
        quiet=False,
        inbrowser=True  # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
    )